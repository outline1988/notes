### 4.4 模型选择、欠拟合和过拟合

**过拟合（overfitting）**
过拟合问题的本质我认为就是模型在训练的过程中网络认为训练样本中的一些无关紧要的特征也与标签有关，导致了这种模型训练出了“背答案”的结果。导致这一问题的原因之一是训练集由于样本数过少或训练集不能代表所有分布等原因，导致其没能中和掉无用特征对标签的作用，让模型在训练过程中认为无用特征与结果也有关系。还有可能的原因是模型或者训练本身没能训练出这种泛化能力。

训练误差（training error）就是在训练集中得到的误差，泛化误差（generalization error）就是原始数据分布的误差期望。理论上泛化误差的准确值难以得到，因为原始数据的分布难以准确描述，但是可以通过大数定理在无限逼近。通常我们将模型应用在独立的测试集来估计泛化误差，测试集应该与训练集完全独立。

判断是否发生的过拟合，只要判断模型的训练误差是否小于泛化误差。理想上，训练集和测试集都是原始样本的分布中抽取的，所以在足够数量数据的情况下，训练误差一定等于泛化误差。

**模型选择**
前面所讨论的数据只有两类：训练数据和测试数据。测试集在真正的训练完成前是不可能使用的。如果模型在训练集中发生了过拟合，我们可以通过独立的测试集来检查，但如果测试集不小心通过某种隐蔽的方式干涉到了训练过程，我们便无法判断此时模型是否发生了过拟合。

常用的选择是在训练集和测试集的基础上再增加一个验证集，验证集在模型选择的时候使用。例如K折交叉验证，原始训练数据被分成了K个不重叠的子集。然后执行K此模型训练和验证，每次在K-1个子集上训练，并在剩余的一个子集（该轮中没有被用于训练的子集）上进行验证。最后，通过对K次实验的结果取平均来估计训练和验证误差。

### 4.5 权重衰减

过拟合现象的发生往往导致了某些参数（线性模型）过于巨大，我们往往通过限制参数的巨大来减缓过拟合问题，也就是在损失函数中增加正则项的原因（PRML这本书是这样说的）。

D2L书这样说，过拟合问题的出现在于训练样本少而模型参数复杂，模型太能学了从而学到了由于样本数少而没能中和掉的特征。所以解决过拟合问题一可以提高训练样本的数量，但是这在实际中往往难以做到。二就是降低模型的复杂度（降低模型的学习能力，使得模型能够减少不重要特征的学习），模型的复杂度大体取决于参数的数量以及参数可取值的范围。通过减小模型在许多情况下会由于模型复杂度对参数数量过于敏感而达到一种要么过于简单，要么过于复杂的尴尬处境而失败，例如多输入情况下的多项式拟合模型。还有一种方法就是降低参数可取值的范围，如果让训练的过程中让参数趋向于取得更加靠近0的值，其同样也能限制模型的灵活性，因为此时模型只能在参数小的情况下训练，所以此时模型的复杂性降低了，也就是在损失函数中添加正则项。

但是我觉得以上两种说法都没有将正则化减轻过拟合现象的本质说清，仅仅泛泛的说正则化项是为了减小模型的复杂度（减弱模型学习能力）是很没有道理的，还需要更本质的说清减小模型复杂度究竟对于模型的训练有什么影响，才让训练过程中模型不会学到不想要的特征，从而不出现过拟合问题。所以我们应该从提前让模型认识到哪些特征是不能学的角度来说明正则化减轻过拟合的原因。

为了解决过拟合问题，途径一是从数据的角度进行修改，提高数据的泛化程度，这是解决过拟合问题的最根本途径，但从数据的角度修改很难进行。途径二就是让模型在训练过程中不学会某些特征（特指我们已知的噪声的特征），我们提前拥有了对于该问题怎样的特征对于输出有贡献度，也即我们有先验知识。我们认为，不同特征对于最后的输出应该具有几乎相近或者较低的贡献度，是所有特征共同作用的结果，而不是某个特征过于重要而单独作用导致的输出。所以我们添加了参数的分布为高斯这一先验条件，再来进行训练。高斯的先验分布最终的结果就是在损失函数中添加正则化而形成的权重衰减办法。这种理解的角度就是从让模型避免训练出不必要的特征而提前做出准备，从而减轻过拟合现象。

当然正则化肯定不能限制对于问题所有无关特征的学习，我认为，只能限制对于噪声特征的学习，噪声的随机性和高频特性表现在模型中即为参数过大，所以正则化防止过拟合是防止模型拟合到噪声。如果实在不巧，就是有一些特征在训练集中表现得与标签高度相关，那么正则化显然也阻止不了模型对这个特征的学习。正则化正真阻止的是，我们已知的噪声特性的特征。

*所以是否可以将无关的特征按照模型先训练出来，看看训练出来的参数有怎样的特性，从而在真正训练的时候以先验概率来避免这样的特性。*

权重衰减有用到拉格朗日乘子
[形象理解拉格朗日乘子法](https://zhuanlan.zhihu.com/p/440297403)
[Karush-Kuhn-Tucker (KKT)条件](https://zhuanlan.zhihu.com/p/38163970)

### 4.6 暂退法（Dropout）

**Bias-variance Tradeoff**
模型的选择也拥有类似于参数估计这样的bias-variance tradeoff，因为本质上有监督学习问题本质上是对函数的估计。对于线性模型来说，其只能代表一小部分的模型，显然其拥有很小的方差，但是可能具有很大的偏差，在训练集上也难以将损失降到很低。所以线性模型遇到了合适的数据（比如数据的输入输出本身具有很强的与线性模型类似的关联），其就可以很轻松的学习完成拟合函数的任务，往往不会出现过拟合问题。

而神经网络恰恰相反，其具有很大的灵活性，也必然造成了其拥有巨大的方差和很小的偏差。这里神经网络具有很大的方差是指神经网络可能在同一分布的不同数据下学到完全不同的函数，但其又在本训练集中表现得十分优秀，也即很小的偏差。

其实这也很好理解，神经网络可以拟合的函数远多于线性模型，所以其在特定数据下的训练结果相当于在一个很大的函数空间内指定一个函数，必然拥有很大的灵敏度。而线性模型能够拟合的函数只有很少一部分，训练的结果也就是从这些很小的空间中指定一个，其结果的不确定性因素要小得多。

**暂退法**
模型的平滑度，也即对于一个好的训练结果，输入的微小变化不应该引起输出较大的变化，光滑性从定性的角度应该就是描述某个函数不应该包含很高的频率分量，其与函数对于输入的随机噪声具有适应性有很深的联系。越是光滑的函数（建议改名低频），对于噪声的变化一定是很小的。

暂退法是提高模型平滑度的一个方法，其在前向传播的计算过程中，每层都同时注入噪声，从而提高函数的平滑性。

神经网络过拟合与每一层都依赖于前一层激活值相关，我认为是一个特定的输出过于依赖特定的输入，从而灵敏度过于高，称之为共适应性。通过在暂退法那样，每一层添加噪声，可以有效减弱共适应性，从而降低输入输出灵敏度。

具体做法一是每层添加高斯噪声（书上没具体说怎么操作）；或是每层的神经元按概率消失，具体做法是每层的每个神经元在最后一步过了非线性函数之后，有一定概率$p$（超参数，需要自己设置）变为0（变为0表示了其对下一层的输出没有任何作用），剩下的神经元向上scale（为了保证期望不变）。

暂退法之所以能够减小过拟合现象，无外乎也是减弱了模型学习噪声特征的能力。依我看来，每层的添加噪声，等价于将训练集中的数据复制几份，将复制的几份再添加噪声而形成新的训练集，继续训练。后者由于增加了含有噪声的样本数，从增加样本数的角度解决了过拟合的问题。

### 4.8 数值稳定性和模型初始化

**梯度爆炸**
考虑有如下$d$层神经网络
$$
\mathbf{h}^t=f_t(\mathbf{h}^{t-1})\quad\mathrm{and}\quad y=\ell\circ f_d\circ\ldots\circ f_1(\mathbf{x})
$$
其中$\mathbf{h}^t$表示$t$层的输出，当然也是$t + 1$层的输入，$f_t(\cdot)$表示$t$层的神经网络的输入输出特性。根据链式求导法则和矩阵求导等关系（**注意这是分子布局，分子布局的链式法则是越外层的函数越靠右**），可以得到
$$
\frac{\partial\ell}{\partial\mathbf{W}^t}=\frac{\partial\ell}{\partial\mathbf{h}^d}\frac{\partial\mathbf{h}^d}{\partial\mathbf{h}^{d-1}}...\frac{\partial\mathbf{h}^{t+1}}{\partial\mathbf{h}^t}\frac{\partial\mathbf{h}^t}{\partial\mathbf{W}^t}
$$
这里补充关于矩阵求导的说明：[矩阵求导的本质与分子布局、分母布局的本质（矩阵求导——本质篇）](https://zhuanlan.zhihu.com/p/263777564)

故反向传播就是矩阵乘法，有多少层就有多少个矩阵。而梯度爆炸就是在反向传播，也就是多个矩阵相乘的过程中，某些参数的梯度过于大（就像大于1的数的多次幂）。

**Example**
考虑如下省略了每层的偏移的$d$层MLP，若要计算$t$层的参数的梯度，我们需要计算$d - t$次矩阵乘法
$$
\prod\limits_{i = t}^{d - 1} \frac{\partial \mathbf{h} ^ {i + 1} }{\partial \mathbf{h} ^ {i}}
$$
我们每层都有输入输出特性
$$
f_t(\mathbf{h}^{t-1})=\sigma(\mathbf{W}^t\mathbf{h}^{t-1})
$$
那么每层的梯度可表示为=
$$
\frac{\partial\mathbf{h}^{t}}{\partial\mathbf{h}^{t-1}}=\text{diag}\left(\sigma^{\prime}(\mathbf{W}^{t}\mathbf{h}^{t-1})\right)W^{t}
$$
这里补充关于输入输出都为标量的函数而拓展的输入输出同维度向量的函数，其中向量的每一元素都与输入同一位置的元素相对应，如有函数$f(\mathbf{x}) = 2 \mathbf{x}$。那么此时对该函数求导就是向量关于向量的求导，结果一定为只有对角线有值的矩阵
$$
\frac{\partial \mathbf{y}}{\partial \mathbf{x}}=\begin{bmatrix}\frac{\partial y_1}{\partial x_1}&\frac{\partial y_1}{\partial x_2}&\frac{\partial y_1}{\partial x_3}&\ldots&\frac{\partial y_1}{\partial x_n}\\\vdots&\vdots&\vdots&\ddots&\vdots\\\frac{\partial y_m}{\partial x_1}&\cdots&\cdots&\cdots&\frac{\partial y_m}{\partial x_n}\end{bmatrix}
$$
由于函数的输出向量的每一个元素都只由输入向量相对应位置的元素有关，故只有上述矩阵的对角元素有值，这可以当作一个结论记下。

回到MLP的例子，我们最终可以得到，当要计算$t$层参数$W^{t}$的梯度时，我们要计算
$$
\prod_{i=t}^{d-1}\frac{\partial\mathbf{h}^{i+1}}{\partial\mathbf{h}^i}=\prod_{i=t}^{d-1}\text{diag}\left(\sigma^{\prime}(\mathbf{W}^i\mathbf{h}^{i-1})\right)W^{t}
$$
这么多次的矩阵乘法。如果我们使用ReLU作为激活函数
$$
\sigma(x)=\max(0,x)\quad\text{and}\quad\sigma^{\prime}(x)=\begin{cases}1&\text{if }x>0\\0&\text{otherwise}\end{cases}
$$
那么
$$
\text{diag}\left(\sigma^{\prime}(\mathbf{W}^i\mathbf{h}^{i-1})\right)
$$
就如同单位矩阵的某些行置0了，而我们又知道，当左乘的初等矩阵等效于对右边的矩阵进行行变换，所以左边矩阵某些行置0相当于让右边矩阵的某些行置0。所以最终$\prod_{i=t}^{d-1}\frac{\partial\mathbf{h}^{i+1}}{\partial\mathbf{h}^i}$的元素会来源于$\prod_{i=t}^{d-1}(W^i)^T$的一部分，当$d - t$很大时，就会有可能一些参数的梯度的值就会很大。

梯度爆炸的问题

- 梯度在求解的时候直接超出浮点的表示范围。这是最显而易见的问题，由于在浮点的限制下，过大的数值一定是不能被浮点表示的；
- 神经网络的训练对学习率十分敏感。由于梯度下降依靠参数梯度的值对参数进行更新，如果梯度值很大，而学习率没有相应中和掉这个很大的梯度，就会导致更新后的参数很大，又由于参数的梯度本身就是和参数自己有关的（前面的梯度表达式中可以看见），所以参数越大，继续求出来的参数的梯度就更大，如此正向反馈，最终训练爆炸。

**梯度消失**
而梯度消失就是在反向传播，也就是多个矩阵相乘的过程中，某些参数的梯度很小（就像小于1的数的多次幂）。还是回到刚才的例子，要计算$t$层参数$W^{t}$的梯度时，我们要计算
$$
\prod_{i=t}^{d-1}\frac{\partial\mathbf{h}^{i+1}}{\partial\mathbf{h}^i}=\prod_{i=t}^{d-1}\text{diag}\left(\sigma^{\prime}(\mathbf{W}^i\mathbf{h}^{i-1})\right)W^{t}
$$
这么多次的矩阵乘法。如果我们使用softmax作为激活函数
$$
\sigma(x)=\frac{1}{1+e^{-x}}\quad\text{and}\quad\sigma^{\prime}(x)=\sigma(x)(1-\sigma(x))
$$
由于$\sigma^{\prime}(x)$的输入输出特性，其只有在很小的范围内具有稍微大一点的值，而在其他地方的值都很小

![image-20231205160712574](C:\Users\outline\AppData\Roaming\Typora\typora-user-images\image-20231205160712574.png)

所以在累乘法之后，$\prod_{i=t}^{d-1}\text{diag}\left(\sigma^{\prime}(\mathbf{W}^i\mathbf{h}^{i-1})\right)W^{t}$之后，有很大部分的参数由于受到$\sigma^{\prime}(x)$的影响而变得很小。

梯度消失的问题：

- 梯度变为0，对相应的参数无论学习率设置为什么，训练都没有进展。
- 更进一步来说，对于一个深层的神经网络，底层的参数由于梯度消失，几乎对于整体没有什么作用，所以你此时再增加网络的层数，也没有什么用。

我对于梯度消失和梯度爆炸的理解，首先梯度消失和梯度下降是由网络模型和损失函数本身决定的，是函数本身的性质不好导致的训练出现问题，而不是由其他的什么因素导致的。就是有可能存在某些点离目标很近，但是该点很陡，梯度十分巨大，虽然梯度指的方向仍然是最优点大致的方向，但是一个步子迈太大了，导致无法到达最优点，甚至正向反馈，趋向混乱。或是有些点离目标很远，但是该点很缓慢，梯度很小，慢慢挪要很久很久才能到达最优点。

**初始化参数**

